2025-07-23 12:17:33.179755: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-23 12:17:33.193954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1753273053.211047   26191 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1753273053.216627   26191 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1753273053.237070   26191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1753273053.237168   26191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1753273053.237231   26191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1753273053.237285   26191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-07-23 12:17:33.241128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:__main__:Loading tokenizer: Qwen/Qwen3-14B
INFO:__main__:Loading model: Qwen/Qwen3-14B
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:05,  1.32it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:01<00:04,  1.27it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:02<00:03,  1.25it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:03<00:03,  1.25it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:03<00:02,  1.24it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:04<00:01,  1.24it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:05<00:00,  1.24it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.51it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.34it/s]
INFO:__main__:Loading dataset: kylebrussell/cap-rlvr-sft in streaming mode
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:__main__:Original dataset columns: ['prompt', 'completion', 'task', 'metadata', 'split', 'source_line']
INFO:__main__:Removing columns: ['prompt', 'completion', 'task', 'metadata', 'split', 'source_line']
INFO:__main__:Tokenizing datasets on the fly...
INFO:__main__:Limiting train samples to 10000
INFO:__main__:Limiting validation samples to 1000
INFO:__main__:Dataset preparation complete. Training will now use the streamed dataset.
INFO:__main__:Estimated training steps: 156
INFO:__main__:Training Configuration:
INFO:__main__:  GPUs: 2
INFO:__main__:  Per-device batch size: 4
INFO:__main__:  Gradient accumulation: 8
INFO:__main__:  Effective batch size: 64
INFO:__main__:  Max steps: 156
INFO:__main__:  Learning rate: 0.0001
INFO:__main__:  Max length: 1024
/lambda/nfs/cap-rlvr/scripts/train_sft_robust.py:224: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
trainable params: 64,225,280 || all params: 14,832,532,480 || trainable%: 0.4330
[2025-07-23 12:17:45,705] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-23 12:17:46,785] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
INFO:__main__:Starting training...
  0%|          | 0/156 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  1%|          | 1/156 [00:07<20:21,  7.88s/it]  1%|▏         | 2/156 [00:14<18:25,  7.18s/it]  2%|▏         | 3/156 [00:20<17:21,  6.81s/it]  3%|▎         | 4/156 [00:27<17:08,  6.77s/it]  3%|▎         | 5/156 [00:34<17:27,  6.94s/it]  4%|▍         | 6/156 [00:41<17:06,  6.85s/it]  4%|▍         | 7/156 [00:48<17:18,  6.97s/it]  5%|▌         | 8/156 [00:55<16:52,  6.84s/it]  6%|▌         | 9/156 [01:02<16:56,  6.91s/it]  6%|▋         | 10/156 [01:08<16:21,  6.72s/it]                                                  6%|▋         | 10/156 [01:08<16:21,  6.72s/it]  7%|▋         | 11/156 [01:15<16:00,  6.62s/it]  8%|▊         | 12/156 [01:21<15:41,  6.54s/it]  8%|▊         | 13/156 [01:27<15:00,  6.30s/it]  9%|▉         | 14/156 [01:33<15:15,  6.45s/it] 10%|▉         | 15/156 [01:40<15:20,  6.53s/it] 10%|█         | 16/156 [01:45<14:17,  6.13s/it] 11%|█         | 17/156 [01:52<14:35,  6.30s/it] 12%|█▏        | 18/156 [01:59<14:48,  6.44s/it] 12%|█▏        | 19/156 [02:06<15:03,  6.59s/it] 13%|█▎        | 20/156 [02:12<14:41,  6.48s/it]                                                 13%|█▎        | 20/156 [02:12<14:41,  6.48s/it] 13%|█▎        | 21/156 [02:18<14:29,  6.44s/it] 14%|█▍        | 22/156 [02:26<15:00,  6.72s/it] 15%|█▍        | 23/156 [02:33<15:08,  6.83s/it] 15%|█▌        | 24/156 [02:40<15:21,  6.98s/it] 16%|█▌        | 25/156 [02:47<15:04,  6.91s/it] 17%|█▋        | 26/156 [02:54<15:05,  6.97s/it] 17%|█▋        | 27/156 [03:01<15:01,  6.99s/it] 18%|█▊        | 28/156 [03:09<15:18,  7.17s/it] 19%|█▊        | 29/156 [03:15<14:43,  6.96s/it] 19%|█▉        | 30/156 [03:22<14:28,  6.89s/it]                                                 19%|█▉        | 30/156 [03:22<14:28,  6.89s/it] 20%|█▉        | 31/156 [03:29<14:26,  6.93s/it] 21%|██        | 32/156 [03:36<14:34,  7.05s/it] 21%|██        | 33/156 [03:43<14:24,  7.03s/it] 22%|██▏       | 34/156 [03:49<13:47,  6.78s/it] 22%|██▏       | 35/156 [03:57<14:05,  6.99s/it] 23%|██▎       | 36/156 [04:04<13:59,  7.00s/it] 24%|██▎       | 37/156 [04:11<13:58,  7.05s/it] 24%|██▍       | 38/156 [04:19<14:09,  7.20s/it] 25%|██▌       | 39/156 [04:26<14:13,  7.29s/it] 26%|██▌       | 40/156 [04:33<13:49,  7.15s/it]                                                 26%|██▌       | 40/156 [04:33<13:49,  7.15s/it] 26%|██▋       | 41/156 [04:40<13:32,  7.07s/it] 27%|██▋       | 42/156 [04:47<13:20,  7.02s/it] 28%|██▊       | 43/156 [04:53<12:57,  6.88s/it] 28%|██▊       | 44/156 [05:00<12:30,  6.70s/it] 29%|██▉       | 45/156 [05:07<12:42,  6.87s/it] 29%|██▉       | 46/156 [05:13<12:21,  6.74s/it] 30%|███       | 47/156 [05:20<12:17,  6.77s/it] 31%|███       | 48/156 [05:26<11:44,  6.52s/it] 31%|███▏      | 49/156 [05:33<11:44,  6.58s/it] 32%|███▏      | 50/156 [05:39<11:41,  6.62s/it]                                                 32%|███▏      | 50/156 [05:39<11:41,  6.62s/it] 33%|███▎      | 51/156 [05:47<12:01,  6.87s/it] 33%|███▎      | 52/156 [05:53<11:21,  6.55s/it] 34%|███▍      | 53/156 [05:58<10:50,  6.32s/it] 35%|███▍      | 54/156 [06:06<11:06,  6.53s/it] 35%|███▌      | 55/156 [06:12<11:12,  6.66s/it] 36%|███▌      | 56/156 [06:19<11:13,  6.73s/it] 37%|███▋      | 57/156 [06:26<10:56,  6.63s/it] 37%|███▋      | 58/156 [06:33<11:08,  6.82s/it] 38%|███▊      | 59/156 [06:40<11:05,  6.86s/it] 38%|███▊      | 60/156 [06:46<10:42,  6.69s/it]                                                 38%|███▊      | 60/156 [06:46<10:42,  6.69s/it] 39%|███▉      | 61/156 [06:53<10:48,  6.83s/it] 40%|███▉      | 62/156 [06:59<10:19,  6.59s/it] 40%|████      | 63/156 [07:07<10:36,  6.84s/it] 41%|████      | 64/156 [07:13<10:17,  6.72s/it] 42%|████▏     | 65/156 [07:20<10:22,  6.84s/it] 42%|████▏     | 66/156 [07:27<10:06,  6.74s/it] 43%|████▎     | 67/156 [07:34<10:15,  6.92s/it] 44%|████▎     | 68/156 [07:41<10:07,  6.90s/it] 44%|████▍     | 69/156 [07:48<09:50,  6.79s/it] 45%|████▍     | 70/156 [07:55<09:53,  6.90s/it]                                                 45%|████▍     | 70/156 [07:55<09:53,  6.90s/it] 46%|████▌     | 71/156 [08:01<09:30,  6.72s/it] 46%|████▌     | 72/156 [08:08<09:31,  6.80s/it] 47%|████▋     | 73/156 [08:15<09:27,  6.84s/it] 47%|████▋     | 74/156 [08:22<09:33,  7.00s/it] 48%|████▊     | 75/156 [08:30<09:30,  7.05s/it] 49%|████▊     | 76/156 [08:37<09:25,  7.07s/it] 49%|████▉     | 77/156 [08:44<09:13,  7.01s/it] 50%|█████     | 78/156 [08:50<09:02,  6.95s/it] 51%|█████     | 79/156 [08:57<08:46,  6.84s/it] 51%|█████▏    | 80/156 [09:04<08:33,  6.75s/it]                                                 51%|█████▏    | 80/156 [09:04<08:33,  6.75s/it] 52%|█████▏    | 81/156 [09:11<08:50,  7.07s/it] 53%|█████▎    | 82/156 [09:18<08:41,  7.05s/it] 53%|█████▎    | 83/156 [09:25<08:18,  6.82s/it] 54%|█████▍    | 84/156 [09:32<08:19,  6.93s/it] 54%|█████▍    | 85/156 [09:38<08:06,  6.85s/it] 55%|█████▌    | 86/156 [09:45<07:58,  6.83s/it] 56%|█████▌    | 87/156 [09:53<08:00,  6.96s/it] 56%|█████▋    | 88/156 [09:59<07:33,  6.67s/it] 57%|█████▋    | 89/156 [10:06<07:40,  6.87s/it] 58%|█████▊    | 90/156 [10:12<07:25,  6.74s/it]                                                 58%|█████▊    | 90/156 [10:12<07:25,  6.74s/it] 58%|█████▊    | 91/156 [10:19<07:18,  6.75s/it] 59%|█████▉    | 92/156 [10:26<07:19,  6.87s/it] 60%|█████▉    | 93/156 [10:33<07:09,  6.81s/it] 60%|██████    | 94/156 [10:40<07:00,  6.78s/it] 61%|██████    | 95/156 [10:46<06:47,  6.68s/it] 62%|██████▏   | 96/156 [10:52<06:29,  6.50s/it] 62%|██████▏   | 97/156 [10:59<06:33,  6.67s/it] 63%|██████▎   | 98/156 [11:06<06:30,  6.73s/it] 63%|██████▎   | 99/156 [11:13<06:30,  6.85s/it] 64%|██████▍   | 100/156 [11:19<06:11,  6.64s/it]                                                  64%|██████▍   | 100/156 [11:19<06:11,  6.64s/it]                                                  64%|██████▍   | 100/156 [12:22<06:11,  6.64s/it] 65%|██████▍   | 101/156 [12:32<24:06, 26.30s/it] 65%|██████▌   | 102/156 [12:39<18:27, 20.52s/it] 66%|██████▌   | 103/156 [12:45<14:28, 16.39s/it] 67%|██████▋   | 104/156 [12:52<11:35, 13.37s/it] 67%|██████▋   | 105/156 [12:59<09:51, 11.60s/it] 68%|██████▊   | 106/156 [13:06<08:35, 10.31s/it] 69%|██████▊   | 107/156 [13:14<07:39,  9.38s/it] 69%|██████▉   | 108/156 [13:20<06:49,  8.53s/it] 70%|██████▉   | 109/156 [13:28<06:28,  8.27s/it] 71%|███████   | 110/156 [13:34<05:53,  7.69s/it]                                                  71%|███████   | 110/156 [13:34<05:53,  7.69s/it] 71%|███████   | 111/156 [13:41<05:35,  7.45s/it] 72%|███████▏  | 112/156 [13:48<05:17,  7.23s/it] 72%|███████▏  | 113/156 [13:55<05:05,  7.10s/it] 73%|███████▎  | 114/156 [14:01<04:53,  6.98s/it] 74%|███████▎  | 115/156 [14:09<04:49,  7.07s/it] 74%|███████▍  | 116/156 [14:16<04:42,  7.06s/it] 75%|███████▌  | 117/156 [14:23<04:35,  7.07s/it] 76%|███████▌  | 118/156 [14:29<04:22,  6.92s/it] 76%|███████▋  | 119/156 [14:36<04:13,  6.84s/it] 77%|███████▋  | 120/156 [14:43<04:05,  6.83s/it]                                                  77%|███████▋  | 120/156 [14:43<04:05,  6.83s/it] 78%|███████▊  | 121/156 [14:50<04:02,  6.92s/it] 78%|███████▊  | 122/156 [14:56<03:45,  6.64s/it] 79%|███████▉  | 123/156 [15:02<03:33,  6.46s/it] 79%|███████▉  | 124/156 [15:08<03:22,  6.33s/it] 80%|████████  | 125/156 [15:14<03:15,  6.31s/it] 81%|████████  | 126/156 [15:21<03:10,  6.34s/it] 81%|████████▏ | 127/156 [15:27<03:02,  6.29s/it] 82%|████████▏ | 128/156 [15:34<03:05,  6.62s/it] 83%|████████▎ | 129/156 [15:41<03:05,  6.85s/it] 83%|████████▎ | 130/156 [15:48<02:58,  6.88s/it]                                                  83%|████████▎ | 130/156 [15:48<02:58,  6.88s/it] 84%|████████▍ | 131/156 [15:55<02:51,  6.86s/it] 85%|████████▍ | 132/156 [16:03<02:48,  7.02s/it] 85%|████████▌ | 133/156 [16:09<02:37,  6.86s/it] 86%|████████▌ | 134/156 [16:15<02:24,  6.59s/it] 87%|████████▋ | 135/156 [16:22<02:21,  6.73s/it] 87%|████████▋ | 136/156 [16:28<02:11,  6.57s/it] 88%|████████▊ | 137/156 [16:36<02:10,  6.85s/it] 88%|████████▊ | 138/156 [16:43<02:04,  6.93s/it] 89%|████████▉ | 139/156 [16:50<01:56,  6.86s/it] 90%|████████▉ | 140/156 [16:57<01:51,  6.96s/it]                                                  90%|████████▉ | 140/156 [16:57<01:51,  6.96s/it] 90%|█████████ | 141/156 [17:04<01:45,  7.05s/it] 91%|█████████ | 142/156 [17:11<01:39,  7.14s/it] 92%|█████████▏| 143/156 [17:18<01:32,  7.08s/it] 92%|█████████▏| 144/156 [17:26<01:25,  7.14s/it] 93%|█████████▎| 145/156 [17:31<01:13,  6.67s/it] 94%|█████████▎| 146/156 [17:38<01:07,  6.78s/it] 94%|█████████▍| 147/156 [17:44<00:59,  6.60s/it] 95%|█████████▍| 148/156 [17:52<00:53,  6.73s/it] 96%|█████████▌| 149/156 [17:58<00:47,  6.77s/it] 96%|█████████▌| 150/156 [18:05<00:41,  6.87s/it]                                                  96%|█████████▌| 150/156 [18:05<00:41,  6.87s/it] 97%|█████████▋| 151/156 [18:13<00:35,  7.04s/it] 97%|█████████▋| 152/156 [18:20<00:28,  7.05s/it] 98%|█████████▊| 153/156 [18:27<00:21,  7.01s/it] 99%|█████████▊| 154/156 [18:34<00:14,  7.08s/it] 99%|█████████▉| 155/156 [18:41<00:07,  7.11s/it]100%|██████████| 156/156 [18:49<00:00,  7.13s/it]                                                 100%|██████████| 156/156 [18:50<00:00,  7.13s/it]100%|██████████| 156/156 [18:50<00:00,  7.25s/it]
INFO:__main__:Saving final model...
{'loss': 2.3584, 'grad_norm': 0.6114022731781006, 'learning_rate': 9e-06, 'epoch': 0.06}
{'loss': 2.2367, 'grad_norm': 0.580823540687561, 'learning_rate': 1.9e-05, 'epoch': 0.13}
{'loss': 2.0883, 'grad_norm': 0.4878251552581787, 'learning_rate': 2.9e-05, 'epoch': 0.19}
{'loss': 1.8686, 'grad_norm': 0.319753497838974, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.26}
{'loss': 1.6055, 'grad_norm': 0.3826032876968384, 'learning_rate': 4.9e-05, 'epoch': 0.32}
{'loss': 1.3969, 'grad_norm': 0.3514048159122467, 'learning_rate': 5.9e-05, 'epoch': 0.38}
{'loss': 1.349, 'grad_norm': 0.16917967796325684, 'learning_rate': 6.9e-05, 'epoch': 0.45}
{'loss': 1.3266, 'grad_norm': 0.17271287739276886, 'learning_rate': 7.900000000000001e-05, 'epoch': 0.51}
{'loss': 1.3202, 'grad_norm': 0.18944714963436127, 'learning_rate': 8.900000000000001e-05, 'epoch': 0.58}
{'loss': 1.2938, 'grad_norm': 0.17051923274993896, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.64}
{'eval_loss': 1.2748075723648071, 'eval_runtime': 62.9582, 'eval_samples_per_second': 15.884, 'eval_steps_per_second': 3.971, 'epoch': 0.64}
{'loss': 1.3175, 'grad_norm': 0.19624824821949005, 'learning_rate': 8.392857142857144e-05, 'epoch': 0.71}
{'loss': 1.2789, 'grad_norm': 0.19833502173423767, 'learning_rate': 6.607142857142857e-05, 'epoch': 0.77}
{'loss': 1.2463, 'grad_norm': 0.18564017117023468, 'learning_rate': 4.8214285714285716e-05, 'epoch': 0.83}
{'loss': 1.3073, 'grad_norm': 0.175456702709198, 'learning_rate': 3.0357142857142857e-05, 'epoch': 0.9}
{'loss': 1.2956, 'grad_norm': 0.1901794970035553, 'learning_rate': 1.25e-05, 'epoch': 0.96}
{'train_runtime': 1130.8645, 'train_samples_per_second': 4.414, 'train_steps_per_second': 0.138, 'train_loss': 1.542727109713432, 'epoch': 1.0}
