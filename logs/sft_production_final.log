2025-07-23 12:05:09.820992: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-23 12:05:09.835414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1753272309.852432   25497 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1753272309.858894   25497 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1753272309.873290   25497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1753272309.873395   25497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1753272309.873461   25497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1753272309.873516   25497 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-07-23 12:05:09.877359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO:__main__:Loading tokenizer: Qwen/Qwen3-14B
INFO:__main__:Loading model: Qwen/Qwen3-14B
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:05,  1.37it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:01<00:04,  1.32it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:02<00:03,  1.30it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:03<00:03,  1.29it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:03<00:02,  1.29it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:04<00:01,  1.28it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:05<00:00,  1.28it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.54it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.38it/s]
INFO:__main__:Loading dataset: kylebrussell/cap-rlvr-sft in streaming mode
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:__main__:Original dataset columns: ['prompt', 'completion', 'task', 'metadata', 'split', 'source_line']
INFO:__main__:Removing columns: ['prompt', 'completion', 'task', 'metadata', 'split', 'source_line']
INFO:__main__:Tokenizing datasets on the fly...
INFO:__main__:Limiting train samples to 1000000
INFO:__main__:Limiting validation samples to 100000
INFO:__main__:Dataset preparation complete. Training will now use the streamed dataset.
INFO:__main__:Estimated training steps: 15625
INFO:__main__:Training Configuration:
INFO:__main__:  GPUs: 2
INFO:__main__:  Per-device batch size: 4
INFO:__main__:  Gradient accumulation: 8
INFO:__main__:  Effective batch size: 64
INFO:__main__:  Max steps: 15625
INFO:__main__:  Learning rate: 0.0001
INFO:__main__:  Max length: 1024
/lambda/nfs/cap-rlvr/scripts/train_sft_robust.py:224: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
trainable params: 64,225,280 || all params: 14,832,532,480 || trainable%: 0.4330
[2025-07-23 12:05:21,914] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-23 12:05:22,996] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
INFO:__main__:Starting training...
  0%|          | 0/15625 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 1/15625 [00:08<34:55:53,  8.05s/it]  0%|          | 2/15625 [00:14<31:23:57,  7.24s/it]  0%|          | 3/15625 [00:21<29:38:24,  6.83s/it]  0%|          | 4/15625 [00:27<29:23:59,  6.78s/it]  0%|          | 5/15625 [00:34<30:06:06,  6.94s/it]  0%|          | 6/15625 [00:41<29:41:36,  6.84s/it]  0%|          | 7/15625 [00:48<30:12:51,  6.96s/it]  0%|          | 8/15625 [00:55<29:39:16,  6.84s/it]  0%|          | 9/15625 [01:02<29:57:07,  6.90s/it]  0%|          | 10/15625 [01:08<29:06:21,  6.71s/it]                                                       0%|          | 10/15625 [01:08<29:06:21,  6.71s/it]  0%|          | 11/15625 [01:15<28:41:01,  6.61s/it]  0%|          | 12/15625 [01:21<28:19:02,  6.53s/it]  0%|          | 13/15625 [01:27<27:15:25,  6.29s/it]  0%|          | 14/15625 [01:33<27:54:58,  6.44s/it]  0%|          | 15/15625 [01:40<28:15:16,  6.52s/it]  0%|          | 16/15625 [01:45<26:31:13,  6.12s/it]  0%|          | 17/15625 [01:52<27:16:09,  6.29s/it]  0%|          | 18/15625 [01:59<27:51:28,  6.43s/it]  0%|          | 19/15625 [02:06<28:31:57,  6.58s/it]  0%|          | 20/15625 [02:12<28:02:18,  6.47s/it]                                                       0%|          | 20/15625 [02:12<28:02:18,  6.47s/it]  0%|          | 21/15625 [02:18<27:51:16,  6.43s/it]  0%|          | 22/15625 [02:26<29:03:37,  6.70s/it]  0%|          | 23/15625 [02:33<29:33:51,  6.82s/it]  0%|          | 24/15625 [02:40<30:12:19,  6.97s/it]  0%|          | 25/15625 [02:47<29:52:14,  6.89s/it]  0%|          | 26/15625 [02:54<30:08:06,  6.95s/it]  0%|          | 27/15625 [03:01<30:13:08,  6.97s/it]  0%|          | 28/15625 [03:08<31:02:00,  7.16s/it]  0%|          | 29/15625 [03:15<30:07:48,  6.95s/it]  0%|          | 30/15625 [03:22<29:50:24,  6.89s/it]                                                       0%|          | 30/15625 [03:22<29:50:24,  6.89s/it]  0%|          | 31/15625 [03:29<30:00:05,  6.93s/it]  0%|          | 32/15625 [03:36<30:29:09,  7.04s/it]  0%|          | 33/15625 [03:43<30:23:18,  7.02s/it]  0%|          | 34/15625 [03:49<29:19:57,  6.77s/it]  0%|          | 35/15625 [03:57<30:12:58,  6.98s/it]  0%|          | 36/15625 [04:04<30:15:41,  6.99s/it]  0%|          | 37/15625 [04:11<30:28:00,  7.04s/it]  0%|          | 38/15625 [04:18<31:08:40,  7.19s/it]  0%|          | 39/15625 [04:26<31:31:37,  7.28s/it]  0%|          | 40/15625 [04:33<30:55:10,  7.14s/it]                                                       0%|          | 40/15625 [04:33<30:55:10,  7.14s/it]  0%|          | 41/15625 [04:40<30:33:10,  7.06s/it]  0%|          | 42/15625 [04:46<30:21:34,  7.01s/it]  0%|          | 43/15625 [04:53<29:44:04,  6.87s/it]  0%|          | 44/15625 [04:59<28:57:30,  6.69s/it]  0%|          | 45/15625 [05:06<29:40:02,  6.86s/it]  0%|          | 46/15625 [05:13<29:08:28,  6.73s/it]  0%|          | 47/15625 [05:20<29:15:09,  6.76s/it]  0%|          | 48/15625 [05:26<28:10:15,  6.51s/it]  0%|          | 49/15625 [05:32<28:26:04,  6.57s/it]  0%|          | 50/15625 [05:39<28:36:28,  6.61s/it]                                                       0%|          | 50/15625 [05:39<28:36:28,  6.61s/it]  0%|          | 51/15625 [05:47<29:40:59,  6.86s/it]  0%|          | 52/15625 [05:52<28:17:39,  6.54s/it]  0%|          | 53/15625 [05:58<27:16:40,  6.31s/it]  0%|          | 54/15625 [06:05<28:13:00,  6.52s/it]  0%|          | 55/15625 [06:12<28:45:11,  6.65s/it]  0%|          | 56/15625 [06:19<29:04:05,  6.72s/it]  0%|          | 57/15625 [06:25<28:36:42,  6.62s/it]  0%|          | 58/15625 [06:33<29:25:30,  6.80s/it]  0%|          | 59/15625 [06:40<29:36:24,  6.85s/it]  0%|          | 60/15625 [06:46<28:52:39,  6.68s/it]                                                       0%|          | 60/15625 [06:46<28:52:39,  6.68s/it]  0%|          | 61/15625 [06:53<29:28:23,  6.82s/it]  0%|          | 62/15625 [06:59<28:27:33,  6.58s/it]  0%|          | 63/15625 [07:06<29:30:21,  6.83s/it]  0%|          | 64/15625 [07:13<28:58:13,  6.70s/it]  0%|          | 65/15625 [07:20<29:31:22,  6.83s/it]  0%|          | 66/15625 [07:26<29:03:27,  6.72s/it]  0%|          | 67/15625 [07:34<29:49:51,  6.90s/it]  0%|          | 68/15625 [07:41<29:46:47,  6.89s/it]  0%|          | 69/15625 [07:47<29:17:24,  6.78s/it]  0%|          | 70/15625 [07:54<29:45:21,  6.89s/it]                                                       0%|          | 70/15625 [07:54<29:45:21,  6.89s/it]  0%|          | 71/15625 [08:01<28:58:00,  6.70s/it]  0%|          | 72/15625 [08:07<29:19:37,  6.79s/it]  0%|          | 73/15625 [08:14<29:29:53,  6.83s/it]  0%|          | 74/15625 [08:22<30:10:25,  6.99s/it]  0%|          | 75/15625 [08:29<30:23:49,  7.04s/it]  0%|          | 76/15625 [08:36<30:30:42,  7.06s/it]  0%|          | 77/15625 [08:43<30:12:43,  7.00s/it]  0%|          | 78/15625 [08:50<29:58:01,  6.94s/it]  1%|          | 79/15625 [08:56<29:29:26,  6.83s/it]  1%|          | 80/15625 [09:03<29:06:45,  6.74s/it]                                                       1%|          | 80/15625 [09:03<29:06:45,  6.74s/it]  1%|          | 81/15625 [09:11<30:29:36,  7.06s/it]  1%|          | 82/15625 [09:18<30:23:42,  7.04s/it]  1%|          | 83/15625 [09:24<29:24:31,  6.81s/it]  1%|          | 84/15625 [09:31<29:53:15,  6.92s/it]  1%|          | 85/15625 [09:38<29:30:25,  6.84s/it]  1%|          | 86/15625 [09:44<29:25:47,  6.82s/it]  1%|          | 87/15625 [09:52<29:58:55,  6.95s/it]  1%|          | 88/15625 [09:58<28:43:51,  6.66s/it]  1%|          | 89/15625 [10:05<29:36:49,  6.86s/it]  1%|          | 90/15625 [10:11<29:04:18,  6.74s/it]                                                       1%|          | 90/15625 [10:11<29:04:18,  6.74s/it]  1%|          | 91/15625 [10:18<29:04:47,  6.74s/it]  1%|          | 92/15625 [10:25<29:34:42,  6.86s/it]  1%|          | 93/15625 [10:32<29:20:45,  6.80s/it]  1%|          | 94/15625 [10:39<29:13:16,  6.77s/it]  1%|          | 95/15625 [10:45<28:46:56,  6.67s/it]  1%|          | 96/15625 [10:51<27:58:55,  6.49s/it]  1%|          | 97/15625 [10:58<28:43:55,  6.66s/it]  1%|          | 98/15625 [11:05<29:00:13,  6.72s/it]  1%|          | 99/15625 [11:12<29:31:03,  6.84s/it]  1%|          | 100/15625 [11:18<28:36:07,  6.63s/it]                                                        1%|          | 100/15625 [11:18<28:36:07,  6.63s/it]  1%|          | 101/15625 [11:26<29:27:07,  6.83s/it]  1%|          | 102/15625 [11:33<29:41:36,  6.89s/it]  1%|          | 103/15625 [11:39<29:31:16,  6.85s/it]  1%|          | 104/15625 [11:46<28:48:12,  6.68s/it]  1%|          | 105/15625 [11:53<29:47:52,  6.91s/it]